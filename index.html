<!DOCTYPE html>
<html>
<head>
	<meta charset='utf-8'/>
	<title>Adventures in Deep Learning – Nate Parrott</title>
</head>
<body>
	<h1>Adventures in Deep Learning</h1>
	<p>Over the past couple months, I've been trying to learn more about neural networks and deep learning by implementing various algorithms myself. Here's what I've been up to:</p>
	<section>
		<figure>
			<img src=''/>
			<figcaption>Digits from the MNIST data set.</figcaption>
		</figure>
		
		<a href=''><h2><strong>Handwritten digit recognition</strong> — xx% accuracy on MNIST with convolutional networks</h2></a>
		<p>Classifying handwritten digits 0–9, using the MNIST dataset, as part of the <a>CS1950k</a> course at Brown University. We started by writing a <a>fully-connected multi-layer neural network without using a deep learning framework,</a> implementing backpropogation manually with numpy. Then, we built a <a>fully-connected network in Tensorflow</a>. Finally, following the <a>Deep MNIST tutorial</a> on the Tensorflow website, we build a <a>convolutional network</a> that achieved xx% accuracy on the test dataset.</p>
	</section>
	
	<section>
		<figure>
			<img src=''/>
			<figcaption>"Fake" MNIST digits generated by the DCGAN.</figcaption>
		</figure>
		
		<a href=''><h2><strong>Generating plausible, fake handwritten digits</strong> with deep convolutional generative adversarial networks.</h2></a>
		<p>
			Deep convolutional generative adversarial networks (DCGANs) are a really interesting approach to the problem of generative "plasusible fakes" that <em>look like</em> something that could have come from a real-world dataset, but are actually randomly generated. DCGANs are essentially <em>two networks</em> — a "generator" that generates images, and a "discriminator" that is trained to guess whether an image comes from the real dataset, or wwas generated by the generator. The two are alternatingly trained — when the generator is being trained, error is <em>backpropogated through the disciminator first</em>, trying to maximize the featues that cause the discriminator to think the generator's output is real.
		</p>
		<p>
			The DCGAN proved difficult to train — the learning rate needed to be fine-tuned to prevent the generator from collapsing to a single output image. The discriminator seemed to learn much faster than the generator — the discriminator would reach 90% accuracy quickly, while the generator would take 10x more steps to get good enough at "fooling" the discriminator to bring the discriminator accuracy back down to 50%.
		</p>
		<p>
			I'd like to try using generative adversarial models on different images, like <a>ImageNet</a> or faces, or on audio or textual data. I'd also like to experiment with different architectures to make GANs easier to train — training multiple disciminators at once might help by making it less likely for the generator to overfit its output to the particular discriminator's quirks.
		</p>
	</section>
	
	<section>
		<figure>
			<img src=''/>
			<figcaption>A neural network playing the "falling rocks" game using policy gradients.</figcaption>
		</figure>
		
		<a href=''><h2><strong>Playing a simple game</strong> with deep reinforcement learning</h2></a>
		<p>
			<a href=''>DeepMind</a> stunned the machine-learning community in [2013??] by announcing that it had built a single neural network that could learn to play any of 15 Atari games, taking as input only the raw pixels on the screen and a "reward" value that told it when it scored a point. The computer "plays" the game <em>thousands</em> of times, and is trained to take a game-screen image and output the action that's most likely to lead to rewards down the line.
		</p>
		<p>
			Rather than an Atari game, I wrote a <em>very simple</em> game for the computer to play — "rocks" fall from random positions at the top of the screen, and the player moves their "paddle" horizontally to catch them. Teaching a network to play the game was more difficult than I expected. Using <a>Deep Q-Learning</a> like Deepmind did, I was able to train a pretty good AI to play the 8-by-8-square version of the game — but I had trouble training one to be successful on the 16x16 version. I switched to using <a>policy gradients</a> — a slightly simpler approach — and was able to train a successful player on the 16x16 version. Unlike the Deepmind paper, neither of these networks were convolutional — convolutional versions of these networks didn't seem to converge quickly, and I'm not sure the game was complex enough for them to have had any benefit.
		</p>
	</section>
	
	<section>
		<figure>
			<img src=''/>
			<figcaption>A sample image from CIFAR, and the network's predictions of what it might be.</figcaption>
		</figure>
		
		<a href=''><h2><strong>Recognizing real-world images</strong> — xx% accuracy on CIFAR-10 using convolutional networks</h2></a>
		<p>TODO</p>
	</section>
	
	<section>
		<figure>
			<img src=''/>
			<figcaption>A "style" image, a "content" image, and the mixture of both images using style transfer.</figcaption>
		</figure>
		
		<a href=''><h2><strong>Neural style transfer</strong></h2></a>
		<p>TODO</p>
	</section>
	
</body>
</html>
